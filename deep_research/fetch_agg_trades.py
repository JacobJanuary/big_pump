"""
–ó–∞–≥—Ä—É–∑–∫–∞ Binance aggTrades (daily dumps) –¥–ª—è Delta Reversal –±—ç–∫—Ç–µ—Å—Ç–∏–Ω–≥–∞.

–°–∫–∞—á–∏–≤–∞–µ—Ç daily ZIP —Ñ–∞–π–ª—ã, —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç 48—á –æ–∫–Ω–æ –ø–æ—Å–ª–µ —Å–∏–≥–Ω–∞–ª–∞, –∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤ –ë–î.
"""
import os
import sys
import zipfile
import csv
from pathlib import Path
from datetime import datetime, timezone, timedelta
from collections import defaultdict
import requests
import hashlib
import secrets

# Add scripts directory to path
current_dir = Path(__file__).resolve().parent
sys.path.append(str(current_dir))

from pump_analysis_lib import get_db_connection

# Configuration
BASE_URL = "https://data.binance.vision"
DATA_DIR = Path(__file__).resolve().parent.parent / "data" / "agg_trades"
FUTURES_PATH = "data/futures/um/daily/aggTrades"

def get_signals_for_loading(conn, limit=None):
    """–ü–æ–ª—É—á–∏—Ç—å —Å–∏–≥–Ω–∞–ª—ã –∏–∑ web.signal_analysis."""
    query = """
        SELECT 
            sa.id,
            sa.pair_symbol,
            sa.signal_timestamp,
            sa.entry_time
        FROM web.signal_analysis sa
        ORDER BY sa.signal_timestamp ASC
    """
    if limit:
        query += f" LIMIT {limit}"
    
    with conn.cursor() as cur:
        cur.execute(query)
        rows = cur.fetchall()
    
    return [{'id': r[0], 'pair_symbol': r[1], 'signal_timestamp': r[2], 'entry_time': r[3]} for r in rows]

def get_required_dates(signal_timestamp):
    """
    –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–∞–∫–∏–µ –¥–Ω–∏ –Ω—É–∂–Ω–æ —Å–∫–∞—á–∞—Ç—å –¥–ª—è 48—á –æ–∫–Ω–∞.
    
    Returns: list of date strings ['2025-01-01', '2025-01-02', '2025-01-03']
    """
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ UTC –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if signal_timestamp.tzinfo is None:
        signal_timestamp = signal_timestamp.replace(tzinfo=timezone.utc)
    
    start_date = signal_timestamp.date()
    end_date = (signal_timestamp + timedelta(hours=48)).date()
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –¥–∞—Ç—ã –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ
    dates = []
    current = start_date
    while current <= end_date:
        dates.append(current.strftime('%Y-%m-%d'))
        current += timedelta(days=1)
    
    return dates

def download_daily_file(symbol: str, date: str) -> Path | None:
    """
    –°–∫–∞—á–∞—Ç—å daily aggTrades ZIP —Ñ–∞–π–ª.
    
    Returns: Path to downloaded file or None if failed.
    """
    filename = f"{symbol}-aggTrades-{date}.zip"
    url = f"{BASE_URL}/{FUTURES_PATH}/{symbol}/{filename}"
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    symbol_dir = DATA_DIR / symbol
    symbol_dir.mkdir(parents=True, exist_ok=True)
    dest_path = symbol_dir / filename
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —É–∂–µ
    if dest_path.exists():
        print(f"    ‚è≠Ô∏è –£–∂–µ —Å–∫–∞—á–∞–Ω: {filename}")
        return dest_path
    
    try:
        print(f"    üì• –°–∫–∞—á–∏–≤–∞—é: {filename}...", end=' ', flush=True)
        response = requests.get(url, stream=True, timeout=300)
        
        if response.status_code == 404:
            print(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω")
            return None
        
        response.raise_for_status()
        
        with open(dest_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
        
        size_mb = dest_path.stat().st_size / 1024 / 1024
        print(f"‚úÖ {size_mb:.1f} MB")
        return dest_path
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return None

def extract_and_filter_trades(zip_path: Path, start_ms: int, end_ms: int):
    """
    –†–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å ZIP –∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å —Ç—Ä–µ–π–¥—ã –ø–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–º—É –æ–∫–Ω—É.
    
    CSV —Ñ–æ—Ä–º–∞—Ç: agg_trade_id,price,quantity,first_trade_id,last_trade_id,transact_time,is_buyer_maker
    
    Returns: list of trade dicts
    """
    trades = []
    
    try:
        with zipfile.ZipFile(zip_path, 'r') as zf:
            # –í –∞—Ä—Ö–∏–≤–µ –æ–¥–∏–Ω CSV —Ñ–∞–π–ª
            csv_filename = zf.namelist()[0]
            
            with zf.open(csv_filename) as f:
                # –ß–∏—Ç–∞–µ–º –∫–∞–∫ —Ç–µ–∫—Å—Ç
                import io
                text_file = io.TextIOWrapper(f, encoding='utf-8')
                reader = csv.reader(text_file)
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                next(reader, None)
                
                for row in reader:
                    # agg_trade_id,price,quantity,first_trade_id,last_trade_id,transact_time,is_buyer_maker
                    transact_time = int(row[5])
                    
                    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
                    if start_ms <= transact_time <= end_ms:
                        trades.append({
                            'agg_trade_id': int(row[0]),
                            'price': float(row[1]),
                            'quantity': float(row[2]),
                            'transact_time': transact_time,
                            'is_buyer_maker': row[6].lower() == 'true'
                        })
    except Exception as e:
        print(f"    ‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è ZIP: {e}")
    
    return trades

def insert_trades(conn, signal_id: int, pair_symbol: str, trades: list):
    """–í—Å—Ç–∞–≤–∏—Ç—å —Ç—Ä–µ–π–¥—ã –≤ web.agg_trades –∏—Å–ø–æ–ª—å–∑—É—è COPY (psycopg3)."""
    if not trades:
        return 0
    
    import io
    
    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è COPY (TSV —Ñ–æ—Ä–º–∞—Ç)
    buffer = io.StringIO()
    for t in trades:
        buffer.write(f"{signal_id}\t{pair_symbol}\t{t['agg_trade_id']}\t{t['price']}\t{t['quantity']}\t{t['transact_time']}\t{t['is_buyer_maker']}\n")
    
    buffer.seek(0)
    
    # psycopg3 COPY —Å–∏–Ω—Ç–∞–∫—Å–∏—Å
    with conn.cursor() as cur:
        with cur.copy("COPY web.agg_trades (signal_analysis_id, pair_symbol, agg_trade_id, price, quantity, transact_time, is_buyer_maker) FROM STDIN") as copy:
            while data := buffer.read(65536):
                copy.write(data)
    
    return len(trades)

def process_signal(sig):
    """
    –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ–¥–∏–Ω —Å–∏–≥–Ω–∞–ª (–¥–ª—è multiprocessing).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (signal_id, trades_list) –∏–ª–∏ (signal_id, None) –ø—Ä–∏ –æ—à–∏–±–∫–µ.
    """
    signal_id = sig['id']
    symbol = sig['pair_symbol']
    signal_ts = sig['signal_timestamp']
    
    # –í—ã—á–∏—Å–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –æ–∫–Ω–æ (48—á –ø–æ—Å–ª–µ —Å–∏–≥–Ω–∞–ª–∞)
    if signal_ts.tzinfo is None:
        signal_ts = signal_ts.replace(tzinfo=timezone.utc)
    
    start_ms = int(signal_ts.timestamp() * 1000)
    end_ms = int((signal_ts + timedelta(hours=48)).timestamp() * 1000)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω—É–∂–Ω—ã–µ –¥–∞—Ç—ã
    dates = get_required_dates(signal_ts)
    
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    TEMP_DIR = DATA_DIR / "temp_processing"
    TEMP_DIR.mkdir(parents=True, exist_ok=True)
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    temp_filename = f"{signal_id}_{start_ms}_{secrets.token_hex(4)}.tsv.gz"
    temp_path = TEMP_DIR / temp_filename

    # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª—ã –∏ –ø–∏—à–µ–º —Å—Ä–∞–∑—É –≤ TSV (gz)
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º gzip –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –º–µ—Å—Ç–∞ –∏ IO
    import gzip
    
    has_trades = False
    
    try:
        with gzip.open(temp_path, 'wt', encoding='utf-8') as tsv_out:
            for date in dates:
                zip_path = download_daily_file(symbol, date)
                if zip_path:
                    # –ß–∏—Ç–∞–µ–º ZIP –∏ —Ñ–∏–ª—å—Ç—Ä—É–µ–º –±–µ–∑ –∑–∞–≥—Ä—É–∑–∫–∏ –≤—Å–µ–≥–æ –≤ RAM
                    # (–ü—Ä—è–º–æ–π —Å—Ç—Ä–∏–º–∏–Ω–≥ –∏–∑ ZIP –≤ GZ –∑–∞–Ω—è–ª –±—ã –º–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏)
                    trades = extract_and_filter_trades(zip_path, start_ms, end_ms)
                    
                    if trades:
                        has_trades = True
                        for t in trades:
                            # signal_id, pair_symbol, agg_trade_id, price, quantity, transact_time, is_buyer_maker
                            tsv_out.write(f"{signal_id}\t{symbol}\t{t['agg_trade_id']}\t{t['price']}\t{t['quantity']}\t{t['transact_time']}\t{t['is_buyer_maker']}\n")
                            
        if not has_trades:
            if temp_path.exists():
                os.remove(temp_path)
            return (signal_id, symbol, None)
            
        return (signal_id, symbol, str(temp_path))
        
    except Exception as e:
        print(f"Error processing {symbol}: {e}")
        if temp_path.exists():
            os.remove(temp_path)
        return (signal_id, symbol, None)

def insert_trades_from_file(conn, file_path):
    """–í—Å—Ç–∞–≤–∏—Ç—å —Ç—Ä–µ–π–¥—ã –∏–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞."""
    import gzip
    
    if not file_path or not os.path.exists(file_path):
        return 0
        
    inserted = 0
    try:
        with gzip.open(file_path, 'rt', encoding='utf-8') as f:
            with conn.cursor() as cur:
                with cur.copy("COPY web.agg_trades (signal_analysis_id, pair_symbol, agg_trade_id, price, quantity, transact_time, is_buyer_maker) FROM STDIN") as copy:
                    while data := f.read(65536):
                        copy.write(data)
                        # Estimate count? No easy way with COPY FROM STDIN without counting lines first.
                        # We'll just trust COPY.
        
        # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        os.remove(file_path)
        return 1 # –í–æ–∑–≤—Ä–∞—â–∞–µ–º 1 –∫–∞–∫ "—É—Å–ø–µ—Ö" (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ –±–µ–∑ —á—Ç–µ–Ω–∏—è)
        
    except Exception as e:
        print(f"Error inserting from {file_path}: {e}")
        return 0

def fetch_agg_trades(limit=None, dry_run=False, workers=12):
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: —Å–∫–∞—á–∞—Ç—å –∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å aggTrades –¥–ª—è –≤—Å–µ—Ö —Å–∏–≥–Ω–∞–ª–æ–≤.
    """
    from multiprocessing import Pool
    
    # –ß–∏—Å—Ç–∏–º temp
    TEMP_DIR = DATA_DIR / "temp_processing"
    if TEMP_DIR.exists():
        import shutil
        shutil.rmtree(TEMP_DIR)
    
    print("üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ AggTrades (Daily Dumps) - 48—á –æ–∫–Ω–æ")
    print(f"   –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {DATA_DIR}")
    print(f"   –í–æ—Ä–∫–µ—Ä–æ–≤: {workers}")
    print(f"   Temp Dir: {TEMP_DIR}")
    print("-" * 60)
    
    DATA_DIR.mkdir(parents=True, exist_ok=True)
    
    try:
        with get_db_connection() as conn:
            signals = get_signals_for_loading(conn, limit=limit)
            
            if not signals:
                print("‚úÖ –í—Å–µ —Å–∏–≥–Ω–∞–ª—ã —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã")
                return
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º ID —Å–∏–≥–Ω–∞–ª–æ–≤, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö —É–∂–µ –µ—Å—Ç—å aggTrades
            print("Checking existing aggTrades...")
            with conn.cursor() as cur:
                cur.execute("SELECT DISTINCT signal_analysis_id FROM web.agg_trades")
                existing_ids = set(row[0] for row in cur.fetchall())
            print(f"Found {len(existing_ids)} signals with existing aggTrades")
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ, —á—Ç–æ –µ—â—ë –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã
            signals_to_process = [s for s in signals if s['id'] not in existing_ids]
            skipped_count = len(signals) - len(signals_to_process)
            
            if not signals_to_process:
                print(f"‚úÖ –í—Å–µ {len(signals)} —Å–∏–≥–Ω–∞–ª–æ–≤ —É–∂–µ –∏–º–µ—é—Ç aggTrades. –ù–∏—á–µ–≥–æ –¥–µ–ª–∞—Ç—å –Ω–µ –Ω—É–∂–Ω–æ.")
                return
            
            print(f"–ù–∞–π–¥–µ–Ω–æ —Å–∏–≥–Ω–∞–ª–æ–≤: {len(signals)} (–ø—Ä–æ–ø—É—â–µ–Ω–æ: {skipped_count}, –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {len(signals_to_process)})")
            print("-" * 60)
            
            processed = 0
            failed = 0
            
            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞
            with Pool(processes=workers) as pool:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º imap_unordered –¥–ª—è –ø–æ—Ç–æ–∫–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ –º–µ—Ä–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
                for i, (signal_id, symbol, result_path) in enumerate(pool.imap_unordered(process_signal, signals_to_process), 1):
                    
                    if result_path is None:
                        # print(f"[{i}/{len(signals)}] {symbol} - ‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö", end='\r')
                        failed += 1
                        continue
                    
                    if not dry_run:
                        # –í Main Process: –∑–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª –≤ –ë–î
                        insert_trades_from_file(conn, result_path)
                        conn.commit()
                        print(f"[{i}/{len(signals_to_process)}] {symbol} - ‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ")
                    else:
                        print(f"[{i}/{len(signals_to_process)}] {symbol} - [DRY RUN] –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {result_path}")
                        # –í dry-run –Ω–µ —É–¥–∞–ª—è–µ–º —Ñ–∞–π–ª –∏–ª–∏ —É–¥–∞–ª—è–µ–º? –£–¥–∞–ª–∏–º —á—Ç–æ–±—ã –º—É—Å–æ—Ä –Ω–µ –∫–æ–ø–∏—Ç—å.
                        if os.path.exists(result_path):
                            os.remove(result_path)
                    
                    processed += 1
            
            print("\n" + "=" * 60)
            print(f"üìä –ò—Ç–æ–≥–æ:")
            print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å–∏–≥–Ω–∞–ª–æ–≤: {processed}")
            print(f"   –ü—Ä–æ–ø—É—â–µ–Ω–æ: {failed}")
            
    except Exception as e:
        try:
             # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ø—É–ª –µ—Å–ª–∏ –±—ã–ª–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞
             pool.terminate()
        except:
             pass
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='–ó–∞–≥—Ä—É–∑–∫–∞ Binance aggTrades')
    parser.add_argument('--limit', type=int, default=None, help='–õ–∏–º–∏—Ç —Å–∏–≥–Ω–∞–ª–æ–≤')
    parser.add_argument('--dry-run', action='store_true', help='–¢–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å —á—Ç–æ –±—É–¥–µ—Ç —Å–¥–µ–ª–∞–Ω–æ')
    parser.add_argument('--workers', type=int, default=12, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –≤–æ—Ä–∫–µ—Ä–æ–≤')
    
    args = parser.parse_args()
    
    fetch_agg_trades(limit=args.limit, dry_run=args.dry_run, workers=args.workers)

